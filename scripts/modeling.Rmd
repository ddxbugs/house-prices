---
title: "model"
author: "ddxbugs"
date: "2024-05-27"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
sessionInfo()
getwd()

set.seed(1234)

if (!require(caret)) install.packages("caret")
if (!require(lmboot)) install.packages("lmboot")
if (!require(glmnet)) install.packages("glmnet")
if (!require(olsrr)) install.packages("olsrr")
if (!require(car)) install.packages("car")
if (!require(boot)) install.packages("boot")
if (!require(gridExtra)) install.packages("gridExtra")
if (!require(scales)) install.packages("scales")
if (!require(ipred)) install.packages("ipred")
if (!require(randomForest)) install.packages("randomForest")
if (!require(caretEnsemble)) install.packages("caretEnsemble")
if (!require(tidyverse)) install.packages("tidyverse")
if (!require(rgl)) install.packages("rgl")
library(caret)
library(glmnet)
library(olsrr)
library(car)
library(lmboot)
library(boot)
library(gridExtra)
library(scales)
library(ipred)
library(randomForest)
library(caretEnsemble)
library(tidyverse)
library(rgl)
```

## Import the data
```{r}
processed_data <- read.csv("../data/processed/processed_data.csv")
```

## Transform the data
```{r}
# Factorize variable data types
processed_data$LandContour <- factor(processed_data$LandContour)
processed_data$LotConfig <- factor(processed_data$LotConfig)
processed_data$Neighborhood <- factor(processed_data$Neighborhood)
processed_data$BldgType <- factor(processed_data$BldgType)
#processed_data$OverallQual <- factor(processed_data$OverallQual)
#processed_data$OverallCond <- factor(processed_data$OverallCond)
#processed_data$YearBuilt <- factor(processed_data$YearBuilt)
processed_data$CentralAir <- factor(processed_data$CentralAir)
processed_data$PavedDrive <- factor(processed_data$PavedDrive)

# Store distinct data type values
land_contour <- processed_data %>% distinct(LandContour) %>% pull(LandContour)
lot_config <- processed_data %>% distinct(LotConfig) %>% pull(LotConfig)
neighborhood <- processed_data %>% distinct(Neighborhood) %>% pull(Neighborhood)
bldg_type <- processed_data %>% distinct(BldgType) %>% pull(BldgType)
overall_qual <- processed_data %>% distinct(OverallQual) %>% pull(OverallQual)
overall_cond <- processed_data %>% distinct(OverallCond) %>% pull(OverallCond)
year_built <- processed_data %>% distinct(YearBuilt) %>% pull(YearBuilt)
central_air <- processed_data %>% distinct(CentralAir) %>% pull(CentralAir)
tot_rms_abv_grd <- processed_data %>% distinct(TotRmsAbvGrd) %>% pull(TotRmsAbvGrd)
fireplaces <- processed_data %>% distinct(Fireplaces) %>% pull(Fireplaces)
paved_drive <- processed_data %>% distinct(PavedDrive) %>% pull(PavedDrive)

# Create transformed data set 
transformed_data <- processed_data %>% select(-X) # %>% mutate(SalePrice=log(SalePrice))

# Define the list of predictors
predictors <- c("LandContour", "LotConfig", "Neighborhood", "BldgType", 
                "OverallQual", "OverallCond", "YearBuilt", "CentralAir", 
                "X1stFlrSF", "X2ndFlrSF", "TotRmsAbvGrd", "Fireplaces", "PavedDrive")
```

## Build a model
```{r}
fit <- lm(SalePrice~., data=transformed_data)
summary(fit)
anova(fit)
confint(fit)
plot(fit)
hist(fit$residuals, main="Histogram of Residuals", xlab="Residuals")
vif(fit)
barplot(vif(fit), main="VIF Values", horiz=TRUE, col="lightblue")
```

## Feature Selection
```{r}
# ols_step_backward_p(fit, prem=0.05, details=FALSE)
# ols_step_forward_p(fit, penter=0.05, details=FALSE)
ols_step_both_p(fit, prem=0.05, penter=0.05, details=TRUE)
```

## Stepwise selection MLR model
```{r}
stepwise_fit <- lm(log(SalePrice) ~ OverallQual + X1stFlrSF + X2ndFlrSF + YearBuilt + OverallCond + Fireplaces + CentralAir + BldgType + Neighborhood + LandContour + TotRmsAbvGrd, data=transformed_data)
summary(stepwise_fit)
anova(stepwise_fit)
confint(stepwise_fit)
plot(stepwise_fit)
hist(stepwise_fit$residuals, breaks="Sturges", main="Histogram of Residuals", xlab="Residuals")
vif(stepwise_fit)
barplot(vif(stepwise_fit), main="VIF Values", horiz=TRUE, col="lightblue")
```

## Custom model
```{r}
reduced_fit <- lm(log(SalePrice) ~ OverallQual + X1stFlrSF + X2ndFlrSF + YearBuilt + OverallCond + BldgType + Neighborhood,
                  data=transformed_data)
summary(reduced_fit)
anova(reduced_fit)
confint(reduced_fit)
plot(reduced_fit)
hist(reduced_fit$residuals, breaks="Sturges", main="Histogram of Residuals", xlab="Residuals")
vif(reduced_fit)
barplot(vif(reduced_fit), main="VIF Values", horiz=TRUE, col="lightblue")
```


## OBJECTIVE 1
```{r}
# Building models

# One model will include OverallCond and OverallQual
model_with = lm(log(SalePrice) ~ ., data = ames)


# One model WILL NOT include OverallCond and OverallQual
model_without = lm(log(SalePrice) ~ . -OverallCond -OverallQual, data = ames)

# One model will ONLY include OverallCond and OverallQual
model_simple = lm(log(SalePrice) ~ OverallCond + OverallQual, data = ames)


# Trying models with ONLY OverallCond OR OverallQual removed

# No OverallCond
fit_qual = lm(log(SalePrice) ~ . -OverallCond, data = ames)

# No OverallQual
fit_cond = lm(log(SalePrice) ~ . - OverallQual, data = ames)


plot(model_with)
```
ANOVA TESTING
```{r}
# Perform F-tests to compare models
anova(model_without, model_with) # Model_with wins
anova(model_simple, model_with) # Model_with wins
anova(fit_qual, model_with) # Model_with wins
anova(fit_cond, model_with) # Model_with wins

# Perform F-test to compare fit_qual VERSUS fit_cond
anova(fit_cond, fit_qual) # No statistically significant difference

## OUR ANOVA F-TESTS SHOW US THAT A SIMPLE MODEL IS THE WORST MODEL FOR FIT.
## ON THE NEXT LEVEL, HAVING A MODEL WITH BOTH PREDICTORS IS BETTER THAN HAVING
## A MODEL WITHOUT BOTH PREDICTORS.
## LASTLY, THERE IS NO SIGNIFICANT DIFFERENCE BETWEEN HAVING ONLY "OverallQual" OR 
## ONLY "OverallCond" IN OUR MODEL, MEANING, IT IS BEST TO HAVE THEM BOTH IN OUR
## FINAL MODEL.
```
CROSS VALIDATION
```{r}
# CROSS VALIDATION

# Load necessary libraries
library(caret)
library(glmnet)

# Define control for cross-validation
control <- trainControl(method = "repeatedcv", number = 10, repeats = 10)

# Train models with glmnet (ridge and lasso regression)
set.seed(321)
cv_model_glmnet_with <- train(log(SalePrice) ~ ., data = ames, method = "glmnet", trControl = control)
cv_model_glmnet_without <- train(log(SalePrice) ~ . -OverallCond -OverallQual, data = ames, method = "glmnet", trControl = control)
cv_model_glmnet_simple <- train(log(SalePrice) ~ OverallCond + OverallQual, data = ames, method = "glmnet", trControl = control)
cv_model_glmnet_qual <- train(log(SalePrice) ~ . -OverallCond, data = ames, method = "glmnet", trControl = control)
cv_model_glmnet_cond <- train(log(SalePrice) ~ . -OverallQual, data = ames, method = "glmnet", trControl = control)

# Extract results for glmnet models
results_glmnet <- rbind(
  data.frame(Model = "With All Predictors", cv_model_glmnet_with$results),
  data.frame(Model = "Without OverallCond and OverallQual", cv_model_glmnet_without$results),
  data.frame(Model = "Only OverallCond and OverallQual", cv_model_glmnet_simple$results),
  data.frame(Model = "Without OverallCond", cv_model_glmnet_qual$results),
  data.frame(Model = "Without OverallQual", cv_model_glmnet_cond$results)
)

# Average the RMSE and R2 for each model
avg_results_glmnet <- results_glmnet %>%
  group_by(Model) %>%
  summarize(
    Avg_RMSE = mean(RMSE),
    Avg_R2 = mean(Rsquared)
  )
```


BOOTSTRAPPING

```{r}
# Perform bootstrapping with 1000 resamples
set.seed(321)
boot_results <- boot(data = ames, statistic = coef.fun, R = 1000)

# Filter out any rows in the bootstrapped statistics that have NA values
valid_t <- apply(boot_results$t, 1, function(row) all(!is.na(row)))
boot_results$t <- boot_results$t[valid_t, ]
boot_results$R <- sum(valid_t)

# Calculate 95% confidence intervals using the percentile method
boot_conf_intervals <- lapply(1:length(coef(lm(log(SalePrice) ~ ., data = ames))), function(i) {
  tryCatch({
    ci <- boot.ci(boot_results, type = "perc", index = i)
    if (is.null(ci)) stop("CI calculation failed")
    return(ci)
  }, error = function(e) {
    cat("Error calculating CI for index", i, ":", e$message, "\n")
    return(NULL)
  })
})

# Print the confidence intervals
names <- names(coef(lm(log(SalePrice) ~ ., data = ames)))
for (i in 1:length(names)) {
  cat("Confidence Interval for", names[i], ":\n")
  print(boot_conf_intervals[[i]])
  cat("\n")
}

# FINDING THE CONFIDENCE INTERVALS FOR OVERALLCOND AND OVERALLQUAL
# Identify the indices for all levels of OverallQual and OverallCond
overall_qual_indices <- grep("^OverallQual", names)
overall_cond_indices <- grep("^OverallCond", names)

# Print the indices for verification
print(overall_qual_indices)
print(overall_cond_indices)

# Extract the confidence intervals for all levels of OverallQual and OverallCond
ci_overall_qual <- lapply(overall_qual_indices, function(i) {
  tryCatch(boot.ci(boot_results, type = "perc", index = i), error = function(e) e)
})

ci_overall_cond <- lapply(overall_cond_indices, function(i) {
  tryCatch(boot.ci(boot_results, type = "perc", index = i), error = function(e) e)
})

# Print the confidence intervals
cat("Confidence Intervals for OverallQual Levels:\n")
for (i in 1:length(ci_overall_qual)) {
  cat("Level", overall_qual_indices[i], ":\n")
  print(ci_overall_qual[[i]])
  cat("\n")
}

cat("Confidence Intervals for OverallCond Levels:\n")
for (i in 1:length(ci_overall_cond)) {
  cat("Level", overall_cond_indices[i], ":\n")
  print(ci_overall_cond[[i]])
  cat("\n")
}
```


## OBJECTIVE 2

# GLMNET
```{r}
# Set k-fold parameters
glmControl <- trainControl(method="repeatedcv", number=5, repeats=1)
# Fit GLMNET
glmnet.fit <- train(log(SalePrice)~., data=transformed_data, method="glmnet", trControl=glmControl)
glmnet.fit
plot(glmnet.fit)

plot(glmnet.fit$finalModel, xvar="lambda", label=TRUE)

# Investigate penalty term coefficients
opt.pen <- glmnet.fit$finalModel$lambdaOpt
coef(glmnet.fit$finalModel, opt.pen)

# Create dummy variable for categorical predictors
dummy_data <- model.matrix(log(SalePrice)~., data=transformed_data)

# Split data into predictor (x) and response (y)
x <- dummy_data
y <- log(transformed_data$SalePrice)
grid <- 10^seq(10, -2, length=100)

# LASSO
lasso.mod <- glmnet(x, y, alpha=1, lambda=grid)
cv.lasso.out <- cv.glmnet(x, y, alpha=1)
plot(cv.lasso.out)
lasso_best_lambda <- cv.lasso.out$lambda.1se
coef(cv.lasso.out, s=lasso_best_lambda)

# RIDGE
ridge.mod <- glmnet(x, y, alpha=0, lambda=grid)
cv.ridge.out <- cv.glmnet(x, y, alpha=0)
plot(cv.ridge.out)
ridge_best_lambda <- cv.ridge.out$lambda.1se
coef(cv.ridge.out, s=ridge_best_lambda)

# Access lambda values
lasso_lambda_min <- cv.lasso.out$lambda.min
lasso_lambda_1se <- cv.lasso.out$lambda.1se
ridge_lambda_min <- cv.ridge.out$lambda.min
ridge_lambda_1se <- cv.ridge.out$lambda.1se

# Compare cross-validated mean squared errors
lasso_mse_min <- min(cv.lasso.out$cvm)
ridge_mse_min <- min(cv.ridge.out$cvm)

print(paste("LASSO MSE (lambda.min):", lasso_mse_min))
print(paste("Ridge MSE (lambda.min):", ridge_mse_min))

# Compare cross-validated errors at lambda.1se
lasso_mse_1se <- cv.lasso.out$cvm[cv.lasso.out$lambda == lasso_lambda_1se]
ridge_mse_1se <- cv.ridge.out$cvm[cv.ridge.out$lambda == ridge_lambda_1se]

print(paste("LASSO MSE (lambda.1se):", lasso_mse_1se))
print(paste("Ridge MSE (lambda.1se):", ridge_mse_1se))

# Predictions
lasso.pred <- predict(lasso.mod, newx=x)
ridge.pred <- predict(ridge.mod, newx=x)

# Back-transform predictions
lasso.pred <- exp(lasso.pred)
ridge.pred <- exp(ridge.pred)

# Performance Metrics
mse_lasso <- mean((transformed_data$SalePrice - lasso.pred)^2)
mse_ridge <- mean((transformed_data$SalePrice - ridge.pred)^2)
rmse_lasso <- sqrt(mse_lasso)
rmse_ridge <- sqrt(mse_ridge)
mae_lasso <- mean(abs(transformed_data$SalePrice - lasso.pred))
mae_ridge <- mean(abs(transformed_data$SalePrice - ridge.pred))
r2_lasso <- 1 - (sum((transformed_data$SalePrice - lasso.pred)^2) / sum((transformed_data$SalePrice - mean(transformed_data$SalePrice))^2))
r2_ridge <- 1 - (sum((transformed_data$SalePrice - ridge.pred)^2) / sum((transformed_data$SalePrice - mean(transformed_data$SalePrice))^2))

# Print performance metrics
cat("LASSO Regression:\n")
cat("MSE:", mse_lasso, "\n")
cat("RMSE:", rmse_lasso, "\n")
cat("MAE:", mae_lasso, "\n")
cat("R-squared:", r2_lasso, "\n\n")

cat("Ridge Regression:\n")
cat("MSE:", mse_ridge, "\n")
cat("RMSE:", rmse_ridge, "\n")
cat("MAE:", mae_ridge, "\n")
cat("R-squared:", r2_ridge, "\n")

```
# Bootstrapping descriptive statistic
```{r}
# Boot function calculates median Sale Price
median.func <- function(x, i) {
  median(x[i])
}
median.func(transformed_data$SalePrice, 1:30)
median(transformed_data$SalePrice)

median.boot <- boot(transformed_data$SalePrice, median.func, R=2000)
median.boot

# Obtain bootstrap statistical CI
boot.ci(median.boot, conf=0.95, type=c("perc", "basic", "bca"))

# Take a sample of 30 observations to estimate median of population
boot.sample <- sample(transformed_data$SalePrice, 30, replace=FALSE)
hist(boot.sample)
median(boot.sample)
# Compute the bootstrap sampling distribution of the median
medians <- c()
B <- 2000
for (i in 1:B) {
  b.sample <- sample(processed_data$SalePrice, 30, replace=TRUE)
  medians[i] <- median(b.sample)
}
# Plot sample Sale Price histogram distribution
hist(medians, main="Bootstrap Sampling Distribution", xlab="Median Sale Price ($ USD)")

# Obtain SE of median
sd(medians)
# 95% confidence interval
quantile(medians, probs=c(0.025,0.975))

# Paired bootstrapping 
boot.p <- paired.boot(log(SalePrice)~., data=transformed_data, B=2000, seed=1234)
# Obtain bootstrap percentile CI for each coefficient
apply(boot.p$bootEstParam, 2, quantile, probs=c(0.025, 0.975))

# Residual bootstrapping (homoscedasticity)
boot.res <- residual.boot(log(SalePrice)~., data=transformed_data, B=2000, seed=1234)
apply(boot.res$bootEstParam, 2, quantile, probs=c(0.025, 0.975))
```

## Compare Bootstrapping vs. T-test result 
```{r}
t.result <- t.test(transformed_data$SalePrice)
xbar <- c()
B <- 2000
for (i in 1:B) {
  b.sample <- sample(transformed_data$SalePrice, 30, replace=TRUE)
  xbar[i] <- mean(b.sample)
}
# Plot xbar Sale Price histogram distribution
hist(xbar, main="Bootstrap Sampling Distribution", xlab="Average Sale Price")
# Obtain SE of the xbar
sd(xbar)
# 95% Confidence interval for population mean
quantile(xbar, probs=c(0.025, 0.975))
t.result$conf.int
# T-test SE of mean
sd(transformed_data$SalePrice)/sqrt(30)
# Bootstrap SE for the mean
sd(xbar)
```

## K-fold Cross Validation 
```{r}
# Create dummy variable for categorical predictors
dummy_data <- model.matrix(log(SalePrice)~., data=transformed_data)

# Split data into predictor (x) and response (y)
x <- dummy_data
y <- log(transformed_data$SalePrice)
data_combined <- as.data.frame(cbind(x, SalePrice = y))

# Set K-fold parameters
knnControl <- trainControl(method="repeatedcv", number=10, repeats=1)
knn.fit <- train(log(SalePrice)~., 
                 data=data_combined, 
                 method="knn", 
                 trControl=knnControl, 
                 tuneGrid=expand.grid(k=c(1:10, 20, 30)))
plot(knn.fit)
knn.fit
```

## Bagging with Multiple Linear Regression
```{r}
# Perform Bagging
bagged_model <- bagging(log(SalePrice)~., data=transformed_data, nbagg=50)

# Predict and plot
predictions <- predict(bagged_model, transformed_data)
plot(transformed_data$X1stFlrSF, log(transformed_data$SalePrice), main = "Bagging with Linear Regression")
lines(transformed_data$X1stFlrSF, predictions, col = "red", lwd = 2)

plot(transformed_data$OverallQual, log(transformed_data$SalePrice), main = "Bagging with Linear Regression")
lines(transformed_data$OverallQual, predictions, col = "red", lwd = 2)

```


## Bootstrapping and Bagging with Random Forest
```{r}
# Fit Random Forest
rf_model <- randomForest(SalePrice~., data = transformed_data, ntree = 50)
# Print model summary
print(rf_model)
# Plot error rate as a function of the number of trees
plot(rf_model)
# Get importance for each predictor
importance(rf_model)
varImpPlot(rf_model)

# Predict and plot
transformed_data$Predictions <- predict(rf_model, transformed_data)
# Confusion matrix
table(predictions, transformed_data$SalePrice)

# Transform data frame long 
transformed_data_long <- transformed_data %>%
    gather(key="Predictor", value="Value", -SalePrice, -Predictions)

ggplot(transformed_data_long, aes(x=Value, y=SalePrice)) +
  geom_point() +
  geom_line(aes(y=Predictions), color="blue") +
  scale_y_continuous(labels=comma) + # Adjust y-axis labeling
  facet_wrap(~Predictor, scales="free_x") + 
  labs(title="Sale Price vs. Predictors",
       x="Predictor Value",
       y="Sale Price ($ USD)") +
  theme_minimal()

```

## Ensemble multiple models
```{r}
# Define training control
# ensembleControl <- trainControl(method = "cv", number = 5, savePredictions = "final")
# 
# # List of models to ensemble
# model_list <- caretList(
#   SalePrice~.,
#   data = transformed_data,
#   trControl = ensembleControl,
#   methodList = c("lm", "glmnet", "rf")
# )
# 
# # Stacking models using linear regression as meta-model
# stackControl <- trainControl(method = "cv", number = 5)
# stacked_model <- caretStack(
#   model_list,
#   method = "glm",
#   trControl = stackControl
# )
# 
# # Predict and plot
# predictions <- predict(stacked_model, newdata = transformed_data)
# ggplot(data, aes(x = x, y = y)) +
#   geom_point() +
#   geom_line(aes(y = predictions), color = "green", size = 1.5) +
#   ggtitle("Ensemble (Stacking)") +
#   theme_minimal()

```


